{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0338472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create -n MediaPipe python=3.9 -y\n",
    "#!conda run -n MediaPipe pip install mediapipe ipykernel\n",
    "#!conda run -n MediaPipe python -m ipykernel install --user --name=MediaPipe --display-name \"Python (MediaPipe)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20b9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2 #to read and process images\n",
    "import matplotlib.pyplot as plt #to show resultant images \n",
    "\n",
    "import cv2 #to read and process images\n",
    "import matplotlib.pyplot as plt #to show resultant images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f663137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Setup\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture('clean_helland.mp4')  # or 'clean_helland.mp4'\n",
    "\n",
    "# Set display window size\n",
    "DISPLAY_WIDTH = 960\n",
    "DISPLAY_HEIGHT = 540\n",
    "\n",
    "# Setup MediaPipe Pose\n",
    "with mp_pose.Pose(static_image_mode=False,\n",
    "                  model_complexity=1,\n",
    "                  smooth_landmarks=True,\n",
    "                  enable_segmentation=False,\n",
    "                  min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process original frame (don't resize here)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_rgb.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image_rgb)\n",
    "\n",
    "        image_rgb.flags.writeable = True\n",
    "        output_frame = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                output_frame,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "            )\n",
    "\n",
    "        # Resize *for display only*, maintaining aspect ratio\n",
    "        h, w = output_frame.shape[:2]\n",
    "        aspect_ratio = w / h\n",
    "        if w > h:\n",
    "            new_w = DISPLAY_WIDTH\n",
    "            new_h = int(DISPLAY_WIDTH / aspect_ratio)\n",
    "        else:\n",
    "            new_h = DISPLAY_HEIGHT\n",
    "            new_w = int(DISPLAY_HEIGHT * aspect_ratio)\n",
    "\n",
    "        resized_output = cv2.resize(output_frame, (new_w, new_h))\n",
    "\n",
    "        # Show frame\n",
    "        cv2.imshow('Pose Estimation (fit to screen)', resized_output)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MediaPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
